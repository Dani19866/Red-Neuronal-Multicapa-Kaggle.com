# üíß Clasificador de Potabilidad de Agua con Red Neuronal (MLP)

Proyecto de Computaci√≥n Emergente (FPTSP25) para la Universidad Metropolitana.

* **Estudiantes:** Eduardo Curiel, Daniel De Oliveira, Vincent Perez
* **Notebook de Kaggle:** üíª [Notebook en Kaggle](https://www.kaggle.com/code/danieldeoliveira00/vincent-eduardo-daniel-proyecto-c-emergente)
* **Informe:** üìÑ `[No listo]`

---

## üéØ 1. Objetivos del Proyecto

### Objetivo General
Dise√±ar, implementar y evaluar una red neuronal multicapa (MLP) para la clasificaci√≥n de potabilidad del agua.
* **Meta de Rendimiento:** Superar el **70%** de exactitud (accuracy) en el conjunto de prueba.
* **Resultado Final:** **67% de exactitud.**

### Objetivos Espec√≠ficos
1.  **Analizar:** Realizar un an√°lisis exploratorio completo del dataset (distribuciones, correlaciones, etc.).
2.  **Preprocesar:** Implementar un pipeline robusto que incluya manejo de nulos, normalizaci√≥n y balanceo de clases (SMOTE).
3.  **Identificar:** Usar m√©todos basados en √°rboles (Random Forest) para identificar las caracter√≠sticas fisicoqu√≠micas m√°s relevantes.
4.  **Dise√±ar:** Dise√±ar una arquitectura de MLP √≥ptima para el problema.

## üö± 2. El Problema y Justificaci√≥n

La contaminaci√≥n del agua es una crisis de salud p√∫blica, especialmente en Venezuela (ej. Lago de Maracaibo y Lago de Valencia). Los an√°lisis tradicionales son lentos y costosos. Este proyecto explora el **Machine Learning** como una alternativa r√°pida y de bajo costo para la monitorizaci√≥n automatizada.

---

## üõ†Ô∏è 3. Pipeline de Datos y Metodolog√≠a

### üìä 3.1. An√°lisis Exploratorio (EDA)

El an√°lisis inicial revel√≥ 3 desaf√≠os clave:
1.  **Valores Nulos:** Datos faltantes en `ph`, `Sulfate` y `Trihalomethanes`.
2.  **Desbalance de Clases:** El dataset estaba desbalanceado (61% No Potable vs 39% Potable).
3.  **Escalas de Datos:** Caracter√≠sticas con escalas, medias y varianzas muy diferentes.

### ‚öôÔ∏è 3.2. Pipeline de Preprocesamiento

Se implement√≥ un pipeline riguroso para preparar los datos:

1.  **Divisi√≥n de Datos:** `train_test_split` (70/30) con `stratify=y` para mantener la proporci√≥n de clases en ambos conjuntos.
2.  **Imputaci√≥n de Nulos:** Se us√≥ `KNNImputer` (con `n_neighbors=30`) para estimar valores faltantes bas√°ndose en sus "vecinos" m√°s cercanos. Se ajust√≥ solo en *train* para evitar *data leakage*.
3.  **Balanceo de Clases:** Se aplic√≥ `SMOTE` (con `sampling_strategy=0.75`) **solo al set de entrenamiento** para crear muestras sint√©ticas de la clase minoritaria ("Potable") y balancear el modelo.
4.  **Normalizaci√≥n:** Se us√≥ `StandardScaler` para reescalar todas las caracter√≠sticas (media 0, desviaci√≥n 1), un paso crucial para el rendimiento de las redes neuronales.

### üîç 3.3. Selecci√≥n de Caracter√≠sticas

Se entren√≥ un `RandomForestClassifier` solo para evaluar la importancia de las caracter√≠sticas, como se plante√≥ en la metodolog√≠a. El resultado mostr√≥ que **todas las 9 caracter√≠sticas eran relevantes**, por lo que se usaron todas en la MLP.

### üß† 3.4. Arquitectura de la Red Neuronal (MLP)

Se dise√±√≥ un modelo `Sequential` en Keras con una fuerte estrategia de regularizaci√≥n para combatir el sobreajuste:

* **Entrada:** `Input(shape=(9,))`
* **Capa Oculta 1:** `Dense(128, 'relu')` + `L2(0.001)` + `BatchNormalization` + `Dropout(0.2)`
* **Capa Oculta 2:** `Dense(64, 'relu')` + `L2(0.001)` + `BatchNormalization` + `Dropout(0.2)`
* **Capa Oculta 3:** `Dense(32, 'relu')` + `L2(0.001)` + `BatchNormalization` + `Dropout(0.2)`
* **Salida:** `Dense(1, 'sigmoid')` (para clasificaci√≥n binaria).

**Compilaci√≥n y Entrenamiento:**
* **Optimizador:** `Nadam` (Learning Rate = 0.0005)
* **P√©rdida:** `binary_crossentropy`
* **Callbacks:**
    * `EarlyStopping` (monitoreando `val_auc`, `patience=25`)
    * `ReduceLROnPlateau` (monitoreando `val_loss`, `patience=8`)
* **Entrenamiento:** 150 √©pocas con `batch_size=64`.

---

## üìâ 4. Resultados y Conclusiones

* **Objetivo de Precisi√≥n:** > 70%
* **Exactitud Final (Accuracy):** **67%**

El objetivo de rendimiento principal **no se cumpli√≥** por un margen del **3%**.

### 4.1. Reporte de Clasificaci√≥n

#### REPORTE DE CLASIFICACION

| Clase       | Precision | Recall | F1-Score | Support |
|-------------|-----------|--------|----------|---------|
| No Potable | 0.71      | 0.82   | 0.76     | 605     |
| Potable    | 0.58      | 0.44   | 0.50     | 378     |

- **Accuracy**: 0.67 (983 muestras)
- **Macro Avg**: 0.64 precision, 0.63 recall, 0.63 f1-score
- **Weighted Avg**: 0.66 precision, 0.67 recall, 0.66 f1-score

**An√°lisis**: El modelo es mucho mejor identificando agua "No Potable" (Recall de 0.82) que agua "Potable" (Recall de 0.44).

### 4.2. Matriz de Confusi√≥n

| (n=983) | Predicci√≥n: No Potable (0) | Predicci√≥n: Potable (1) |
| :--- | :---: | :---: |
| **Real: No Potable (0)** | **TN = 496** | **FP = 109** |
| **Real: Potable (1)** | **FN = 214** | **TP = 164** |

**An√°lisis de Errores Cr√≠ticos:**
* **üî¥ Falsos Positivos (FP): 109** - ¬°El error m√°s peligroso! 109 muestras **no potables** se clasificaron err√≥neamente como **potables**.
* **üü° Falsos Negativos (FN): 214** - 214 muestras **potables** se clasificaron como **no potables**.

### 4.3. Conclusi√≥n General

El modelo MLP, a pesar del robusto preprocesamiento y la arquitectura compleja, no logr√≥ el objetivo del 70%. Esto sugiere que las 9 caracter√≠sticas del dataset pueden no ser suficientes para separar las clases con alta precisi√≥n. El modelo, adem√°s, genera una cantidad preocupante de Falsos Positivos, lo que lo har√≠a riesgoso para una implementaci√≥n real.

---

## üöÄ 5. Trabajo Futuro

1.  **Probar otros modelos:** Comparar con `Random Forest` o `XGBoost`, que suelen ser superiores en datos tabulares.
2.  **Optimizar Hiperpar√°metros:** Usar `GridSearchCV` o `KerasTuner` para encontrar una mejor arquitectura.
3.  **Ingenier√≠a de Caracter√≠sticas:** Crear *ratios* y nuevas interacciones entre las caracter√≠sticas existentes.

## üíª 6. Stack T√©cnico

* Python
* TensorFlow (Keras)
* Scikit-learn
* Imbalanced-learn (SMOTE)
* Pandas
* NumPy
* Matplotlib
* Seaborn
* Missingno
